# LLaMA 2 Blog Generator

A lightweight Streamlit application that generates human-like blog content using a locally hosted **LLaMA 2** model. Designed for low-end systems, this project eliminates the need for cloud-based APIs by running entirely on your machine with a quantized `.ggml` model.

---

## ğŸš€ What It Does

- ğŸ“ Generates blog posts from a topic and selected writing style.
- ğŸ›ï¸ Customizable word length and tone.
- âš¡ Runs efficiently on low-spec laptops using quantized inference.

---

## ğŸ§  Technology Stack

- **LLaMA 2 (Quantized)** â€“ Local language model (e.g., `ggmlv3.q8_0.bin`)
- **CTransformers** â€“ For loading and running LLaMA 2 without GPUs
- **LangChain** â€“ Prompt templating and model invocation
- **Streamlit** â€“ Simple UI for topic input and result display

---

## âœ… Use Cases

- ğŸ“š Quick blog drafts for content creators
- ğŸ§ª Experimentation with LLMs
- ğŸ§‘â€ğŸ“ Educational tool to learn LLM workflows
- ğŸ”Œ API-free solution for writing assistance

---

## ğŸ’» Requirements

- Python 3.9+
- Minimum 8 GB RAM (recommended)
- Local storage for model (~4â€“5 GB)
- 2 CPU cores (minimum)

---

## Result UI:

![Generated Blog Screenshot](result_ui_img/BlogGenerator.png)
